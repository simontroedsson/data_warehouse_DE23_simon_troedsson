# datawarehoue lifecycle course

I learn datawarehouse here

### Glossary
| terminology       | explanation |
| ----------------- | ----------- |
| downstream        | downstream refers to the components that recieves data or output from an earlier stage in the pipeline. Downstream elements are dependant on data or results produced by upstream components.             |
| upstream          | upstream refers to the components that occur earlier in the data flow. These upstream elements are responsible for producing or providing data that will be used by downstream processes           |
| data warehouse    | A data warehouse is a centralized repository that stores large volumes of structured and semi-structured data from various sources within an organization. It is designed to support querying, reporting, and data analysis, enabling businesses to make data-driven decisions. Data warehouses are optimized for read-heavy workloads, meaning they are well-suited for tasks like running complex queries, generating reports, and performing data analysis            |
| cloud computing   | 
Cloud computing is a technology model that provides on-demand access to computing resources over the internet. These resources include servers, storage, databases, networking, software, analytics, and intelligence, all delivered via the cloud rather than on-premises hardware. Cloud computing enables businesses and individuals to use computing resources without having to invest in or manage physical infrastructure            |
| modern data stack | The Modern Data Stack (MDS) is an ecosystem of cloud-based tools and technologies that streamline the process of collecting, storing, transforming, analyzing, and utilizing data. 
Characteristics of the MDS:
1. cloud native: The modern data stack is built on cloud infrastructure, providing scalability, flexibility, and cost efficiency. This eliminates the need for on-premises hardware and complex maintenance.
2. modular: The stack is composed of specialized tools that can be integrated together, allowing organizations to choose the best tools for their needs. This modularity also allows for easy replacement or upgrading of individual components without disrupting the entire system.
3. real-time capabilities: Modern data stacks often support real-time data ingestion, transformation, and analysis, enabling businesses to make decisions based on up-to-date information.
4. ELT VS ETL: The shift from ETL to ELT is a key characteristic of the modern data stack. In ELT, raw data is first loaded into the data warehouse, and then transformed using tools like dbt. This allows for greater flexibility and faster iteration on data transformations.
5. Accessibility and Usability: The modern data stack emphasizes self-service, making data more accessible to non-technical users. BI tools and no-code/low-code platforms empower a wider range of users to interact with and derive insights from data.
6. Automation: Automation is a cornerstone of the modern data stack. Processes like data ingestion, transformation, and orchestration are automated to reduce manual work and minimize errors  |
| idempotent        |             |
| OLAP              |             |
| OLTP              |             |
| virtual warehouse |             |
| external stage    |             |
| data consumer     |             |
| scaling out       |             |
| scaling up        |             |
| snowflake credit  |             |
| securable object  |             |
| snowflake object  |             |
| schema            |             |
| permanent table   |             |
| transient table   |             |
| temporary table   |             |
| time-travel       |             |
| fail-safe         |             |
| view              |             |
| table             |             |
| DML               |             |
| DDL               |             |
| DQL               |             |
| DCL               |             |
